{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Load dataset, train Logistic Regression, and print accuracy**"
      ],
      "metadata": {
        "id": "IiZySB9gWPKp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgIrZ49kVAAr",
        "outputId": "c9bac035-e1f0-4f71-8c02-e7d443090e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "y = (y == 0).astype(int)  # Convert to binary classification\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Apply L1 regularization**"
      ],
      "metadata": {
        "id": "YpTrugNuWX3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model_l1.fit(X_train, y_train)\n",
        "print(\"L1 Regularized Accuracy:\", accuracy_score(y_test, model_l1.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87PVQUpUWamM",
        "outputId": "7eda4fcb-72e8-4893-9b21-d9b06f394838"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Regularized Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Apply L2 regularization**"
      ],
      "metadata": {
        "id": "CGTTq1GfWseZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_l2 = LogisticRegression(penalty='l2', solver='lbfgs')\n",
        "model_l2.fit(X_train, y_train)\n",
        "print(\"L2 Regularized Accuracy:\", accuracy_score(y_test, model_l2.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmin9OKIWuGC",
        "outputId": "3eead630-a660-4154-e2fe-0c7a1637ca53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 Regularized Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Apply Elastic Net Regularization**"
      ],
      "metadata": {
        "id": "yL9uqfUBXBF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_en = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "model_en.fit(X_train, y_train)\n",
        "print(\"Elastic Net Regularized Accuracy:\", accuracy_score(y_test, model_en.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOLDLg50XHtk",
        "outputId": "bea5c2e5-3f76-4ee9-899d-0ae1f49ea7fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Regularized Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Train Logistic Regression for multiclass using One-vs-Rest (OvR)**"
      ],
      "metadata": {
        "id": "-xmLSRUZXJFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ovr = LogisticRegression(multi_class='ovr', solver='lbfgs')\n",
        "model_ovr.fit(X_train, y_train)\n",
        "print(\"OvR Accuracy:\", accuracy_score(y_test, model_ovr.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km1HK2g1XM8V",
        "outputId": "570ce348-4a07-4d16-a5c0-2f2395e641e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvR Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Hyperparameter tuning with GridSearchCV**"
      ],
      "metadata": {
        "id": "9rx8s34QXOXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oZ2jJXGXRec",
        "outputId": "5b8903bf-8ec1-4e93-8af1-9724f3cf3703"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Evaluate using Stratified K-Fold Cross-Validation**"
      ],
      "metadata": {
        "id": "CfpwBouyXS2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(\"Average Accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxu8-0cGXWJy",
        "outputId": "c7f2ccf4-46b0-461a-8b25-b73aded4a2cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Apply RandomizedSearchCV for hyperparameter **"
      ],
      "metadata": {
        "id": "fvFPIH9kXXfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
        "random_search = RandomizedSearchCV(LogisticRegression(), param_distributions=param_dist, n_iter=5, cv=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Accuracy:\", random_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQMI2zgmXdJa",
        "outputId": "bef49439-8cb8-4f52-fe0c-88366f714002"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 10}\n",
            "Best Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Implement One-vs-One (OvO) Multiclass Logistic Regression**"
      ],
      "metadata": {
        "id": "gGjXIZvdXfJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model_ovo = OneVsOneClassifier(LogisticRegression(solver='lbfgs', max_iter=1000))\n",
        "model_ovo.fit(X_train, y_train)\n",
        "\n",
        "print(\"OvO Accuracy:\", accuracy_score(y_test, model_ovo.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY1ZmlC3Xh9o",
        "outputId": "d81e5893-d1cd-4484-963f-37ef126513b5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvO Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Train Logistic Regression and visualize confusion matrix**"
      ],
      "metadata": {
        "id": "zGpG2_xNXvJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "gdQyy05XXy0c",
        "outputId": "e99ec053-2b37-4ae2-a085-060647966841"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Train Logistic Regression and evaluate Precision, Recall, and F1-Score**"
      ],
      "metadata": {
        "id": "By8wYqBZX0Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkYZc-IJX3gJ",
        "outputId": "c4a92db7-08d3-4f08-8b9e-c7327c53e4c0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Train Logistic Regression on imbalanced data using class weights**"
      ],
      "metadata": {
        "id": "n014ODkhX4_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_weighted = LogisticRegression(class_weight='balanced')\n",
        "model_weighted.fit(X_train, y_train)\n",
        "print(\"Weighted Model Accuracy:\", accuracy_score(y_test, model_weighted.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "casNu9ecX8kH",
        "outputId": "b712d635-80d2-4e19-f59e-f96493753a39"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Model Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Train Logistic Regression on Titanic dataset**"
      ],
      "metadata": {
        "id": "Z-eKVjcKX9qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Apply Standardization before Logistic Regression**"
      ],
      "metadata": {
        "id": "XcH2Rs_hYE7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yBx3GiMkm1WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(\"Standardized Model Accuracy:\", accuracy_score(y_test, model.predict(X_test_scaled)))\n"
      ],
      "metadata": {
        "id": "-bsG7P-jYHhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. Evaluate Logistic Regression using ROC-AUC score**"
      ],
      "metadata": {
        "id": "RGZJl9i4YJUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))\n"
      ],
      "metadata": {
        "id": "UbECERBDYMSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. Train Logistic Regression using custom learning rate (C=0.5)**"
      ],
      "metadata": {
        "id": "6l_76Pe_YOBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom = LogisticRegression(C=0.5)\n",
        "model_custom.fit(X_train, y_train)\n",
        "print(\"Custom C Model Accuracy:\", accuracy_score(y_test, model_custom.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "zLxhUXBxYQ4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. Identify important features using model coefficients**"
      ],
      "metadata": {
        "id": "W5HHANHSYSPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "coefs = np.abs(model.coef_)\n",
        "important_features = np.argsort(coefs[0])[-5:]  # Get top 5 features\n",
        "print(\"Top 5 Important Features:\", important_features)\n"
      ],
      "metadata": {
        "id": "kPzbdQT3YVUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. Train Logistic Regression and evaluate Cohen’s Kappa Score**"
      ],
      "metadata": {
        "id": "Z_ZYB_iDYXOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "print(\"Cohen’s Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "qB-EUUrLYZz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. Visualize Precision-Recall Curve**"
      ],
      "metadata": {
        "id": "SSLySiuVYbIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1])\n",
        "\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "frVJeSAIYeeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. Train Logistic Regression with different solvers and compare accuracy**"
      ],
      "metadata": {
        "id": "DYvvakQxYgRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model_solver = LogisticRegression(solver=solver)\n",
        "    model_solver.fit(X_train, y_train)\n",
        "    print(f\"Solver: {solver}, Accuracy: {accuracy_score(y_test, model_solver.predict(X_test))}\")\n"
      ],
      "metadata": {
        "id": "DgFl_-OgYj_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. Train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare accuracy**"
      ],
      "metadata": {
        "id": "x1mXAJALYoPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model_solver = LogisticRegression(solver=solver)\n",
        "    model_solver.fit(X_train, y_train)\n",
        "    print(f\"Solver: {solver}, Accuracy: {accuracy_score(y_test, model_solver.predict(X_test))}\")\n"
      ],
      "metadata": {
        "id": "MD25p8z9Yqnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22. Train Logistic Regression and evaluate using Matthews Correlation Coefficient (MCC)**"
      ],
      "metadata": {
        "id": "4w778XLJYr5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", matthews_corrcoef(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "u16aq71MYvAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23. Train Logistic Regression on both raw and standardized data, compare accuracy**"
      ],
      "metadata": {
        "id": "whCAEAVPYweO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Without scaling\n",
        "model.fit(X_train, y_train)\n",
        "acc_raw = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "acc_scaled = accuracy_score(y_test, model.predict(X_test_scaled))\n",
        "\n",
        "print(\"Accuracy without Scaling:\", acc_raw)\n",
        "print(\"Accuracy with Scaling:\", acc_scaled)\n"
      ],
      "metadata": {
        "id": "YtShHMvRYzmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24. Train Logistic Regression and find the optimal C using cross-validation**"
      ],
      "metadata": {
        "id": "jqeSBXGIY1La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "best_score = 0\n",
        "best_C = None\n",
        "\n",
        "for C in C_values:\n",
        "    model_C = LogisticRegression(C=C)\n",
        "    scores = cross_val_score(model_C, X, y, cv=5)\n",
        "    mean_score = scores.mean()\n",
        "\n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_C = C\n",
        "\n",
        "print(f\"Best C: {best_C} with Accuracy: {best_score}\")\n"
      ],
      "metadata": {
        "id": "kOK-PPBjY4s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**25. Train Logistic Regression, save the trained model using joblib, and load it again to make predictions**"
      ],
      "metadata": {
        "id": "D4spFqSdY61F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, \"logistic_model.pkl\")\n",
        "\n",
        "# Load the model\n",
        "loaded_model = joblib.load(\"logistic_model.pkl\")\n",
        "\n",
        "# Make predictions\n",
        "print(\"Loaded Model Accuracy:\", accuracy_score(y_test, loaded_model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqjYdNcIY9jZ",
        "outputId": "f25861a7-98fd-4869-83fd-a4fe97ca91cc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Model Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0Zgkmxqm3NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### **1. What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "\n",
        "* **Logistic Regression** is used for **classification** tasks (e.g., spam/not spam).\n",
        "* **Linear Regression** is used for **regression** tasks (predicting continuous values).\n",
        "* Logistic Regression outputs probabilities (between 0 and 1) using a **sigmoid function**, while Linear Regression outputs real numbers.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What is the mathematical equation of Logistic Regression?**\n",
        "\n",
        "$$\n",
        "P(y=1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_nx_n)}}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Why do we use the Sigmoid function in Logistic Regression?**\n",
        "\n",
        "* It maps the linear output to a **probability between 0 and 1**, making it suitable for classification.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. What is the cost function of Logistic Regression?**\n",
        "\n",
        "$$\n",
        "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right]\n",
        "$$\n",
        "\n",
        "This is called the **log-loss** or **binary cross-entropy** function.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. What is Regularization in Logistic Regression? Why is it needed?**\n",
        "\n",
        "* Regularization adds a **penalty** to the loss function to prevent **overfitting**.\n",
        "* It discourages overly complex models (large coefficients).\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Explain the difference between Lasso, Ridge, and Elastic Net regression.**\n",
        "\n",
        "* **Lasso (L1):** Adds $\\lambda \\sum |\\beta_j|$; can shrink coefficients to zero (feature selection).\n",
        "* **Ridge (L2):** Adds $\\lambda \\sum \\beta_j^2$; shrinks coefficients but keeps all features.\n",
        "* **Elastic Net:** Combines L1 and L2; balances sparsity and regularization.\n",
        "\n",
        "---\n",
        "\n",
        "### **7. When should we use Elastic Net instead of Lasso or Ridge?**\n",
        "\n",
        "* When features are **correlated** or when **Lasso alone underperforms**.\n",
        "* Elastic Net balances variable selection and coefficient shrinkage.\n",
        "\n",
        "---\n",
        "\n",
        "### **8. What is the impact of the regularization parameter (λ) in Logistic Regression?**\n",
        "\n",
        "* **Higher λ:** More regularization → smaller coefficients → may underfit.\n",
        "* **Lower λ:** Less regularization → risk of overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### **9. What are the key assumptions of Logistic Regression?**\n",
        "\n",
        "* No multicollinearity.\n",
        "* Linear relationship between features and **log-odds**.\n",
        "* Independence of observations.\n",
        "* Large sample size for stable estimates.\n",
        "\n",
        "---\n",
        "\n",
        "### **10. What are some alternatives to Logistic Regression for classification tasks?**\n",
        "\n",
        "* Decision Trees\n",
        "* Random Forest\n",
        "* Support Vector Machines (SVM)\n",
        "* k-Nearest Neighbors (k-NN)\n",
        "* Naïve Bayes\n",
        "* Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "### **11. What are Classification Evaluation Metrics?**\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "* ROC-AUC\n",
        "* Confusion Matrix\n",
        "\n",
        "---\n",
        "\n",
        "### **12. How does class imbalance affect Logistic Regression?**\n",
        "\n",
        "* It can lead to biased predictions toward the **majority class**, reducing model performance for the minority class.\n",
        "\n",
        "---\n",
        "\n",
        "### **13. What is Hyperparameter Tuning in Logistic Regression?**\n",
        "\n",
        "* It involves choosing the best values for parameters like:\n",
        "\n",
        "  * Regularization strength (λ or `C`)\n",
        "  * Penalty type (L1/L2)\n",
        "  * Solver\n",
        "    Using techniques like Grid Search or Random Search.\n",
        "\n",
        "---\n",
        "\n",
        "### **14. What are different solvers in Logistic Regression? Which one should be used?**\n",
        "\n",
        "* **liblinear:** Good for small datasets, supports L1.\n",
        "* **saga:** Large datasets, supports L1, L2, and Elastic Net.\n",
        "* **newton-cg**, **lbfgs:** Good for L2, multiclass.\n",
        "* Choose based on dataset size and regularization type.\n",
        "\n",
        "---\n",
        "\n",
        "### **15. How is Logistic Regression extended for multiclass classification?**\n",
        "\n",
        "* **One-vs-Rest (OvR):** Fits one classifier per class.\n",
        "* **Softmax Regression (Multinomial Logistic Regression):** Predicts all classes in one model using the softmax function.\n",
        "\n",
        "---\n",
        "\n",
        "### **16. What are the advantages and disadvantages of Logistic Regression?**\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "* Simple, interpretable\n",
        "* Efficient for binary classification\n",
        "* Works well with linearly separable data\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "* Poor performance on complex relationships\n",
        "* Assumes linearity in log-odds\n",
        "* Sensitive to multicollinearity\n",
        "\n",
        "---\n",
        "\n",
        "### **17. What are some use cases of Logistic Regression?**\n",
        "\n",
        "* Spam detection\n",
        "* Disease diagnosis (e.g., diabetes prediction)\n",
        "* Customer churn prediction\n",
        "* Credit scoring\n",
        "* Fraud detection\n",
        "\n",
        "---\n",
        "\n",
        "### **18. What is the difference between Softmax Regression and Logistic Regression?**\n",
        "\n",
        "* **Logistic Regression:** Binary classification.\n",
        "* **Softmax Regression:** Multiclass classification with mutually exclusive classes.\n",
        "\n",
        "---\n",
        "\n",
        "### **19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**\n",
        "\n",
        "* **OvR:** Simpler, good for unbalanced classes or when interpretability is key.\n",
        "* **Softmax:** More accurate for balanced and mutually exclusive classes; considers all classes at once.\n",
        "\n",
        "---\n",
        "\n",
        "### **20. How do we interpret coefficients in Logistic Regression?**\n",
        "\n",
        "* Each coefficient represents the **log-odds** change in the outcome for a 1-unit increase in the predictor.\n",
        "* Exponentiating a coefficient ($e^{\\beta}$) gives the **odds ratio**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "d_REPQDlm3wv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mHYaiSQEnL8b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}